# GAN(Generative Adversarial Networks)

### Main idea
- 위조 지폐범(Generator)와 경찰(Discriminator)의 대결
- G는 최대한 진짜 같은 모조품을 만들며, D는 진품과 모조품을 구별한다. 
- 경쟁적 학습을 통해 결국 완전한 모조품을 만드는 것이 목표(위조 지폐범의 승리)  

![image](https://user-images.githubusercontent.com/76815825/112716874-48582000-8f2c-11eb-994f-4a2a2319f10d.png)

GAN은 실존하지는 않지만 있을법한 이미지를 만들어내기 위한 모델로 게임이론의 minimax 알고리즘으로부터 아이디어를 따왔다고 한다. 위조지폐범(G)은 경찰(D)에게 걸리면 더 진짜 같은 위조지폐를 만들려하고 경찰은 위조지폐범을 잡기 위한 기술을 또 만들어내며 서로 발전하게 되는데 이러한 모습 때문에 적대적(Adversarial)이라고 표현한다. 현실과는 달리 이 모델에서는 위조지폐범(G)의 승리를 목표로 하며 결국 경찰(D)이 진짜와 가짜를 분간할 수 없는 지폐(생성 이미지)를 만들어내게 된다.
  
  
### Loss function
GAN의 손실함수는 다음과 같다.

![image](https://user-images.githubusercontent.com/76815825/112717394-b4885300-8f2f-11eb-8359-3a58892ef874.png)

식이 다소 복잡하니 하나하나 뜯어서 해석해보자.  

우변은 다음과 같이 해석할 수 있다.  
Ex-Pdata(x)[logD(x)]: 실제 이미지의 데이터 분포(Pdata(x))에서 하나를 샘플링(x)하여 판별자에 넣었을 때 나온 값의 로그값의 기댓값  
Ez-Pz(z)[log(1-D(G(z)))]: noise 벡터 분포(Pz(z))에서 하나를 샘플링(z)하여 만든 생성이미지(G(z))를 판별자에 넣었을 때 나온 값의 로그값의 기댓값  

판별자D 입장에서는 x는 진짜(1)로 판별하고 z는 가짜(0)로 판별하여야 하므로 우변을 최대화하는 방향으로 학습하게 된다.  
생성자G 입장에서는 D가 G(z)를 1로 판별하게 만들고싶으므로 우변을 최소화하는 방향으로 학습하게 된다.  
  
  
### Optimality
![image](https://user-images.githubusercontent.com/76815825/112717896-db945400-8f32-11eb-8f9d-0c34105e763f.png)

위 그림은 생성자가 학습을 통해 원본데이터로 수렴하면서 목표를 달성하는 모습을 보여준다. 생성 모델의 분포인 초록선은 원본 데이터의 분포인 검정선과 같아지도록 점점 변하며 파란선은 판별 모델의 분포를 의미한다. 학습이 전혀 안 된 상태(a)에서는 불안정한 모습을 보이다가 점차 원본 데이터는 1에 가깝게 생성 데이터는 0에 가깝에 분류하기 시작했고 최종적으로는 1/2로 수렴하게 된다.  
다.  
