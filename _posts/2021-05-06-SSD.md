---
title:  "<논문리뷰> SSD: Single Shot MultiBox Detector"

categories:
  - 논문
tags:
  - 논문
  - Object Detection
classes: wide
typora-copy-images-to: ..\images\2021-05-06
---

# R-CNN

## Abstract
SSD는 다양한 크기(scale)와 종횡비(aspect ratios)의 특징맵을 이용한다는 것이 특징이다. 카테고리 예측 점수와 default box의 조정을 동시애 하는 1-stage detector로
속도를 높이면서도 경쟁력 있는 정확도를 유지했다는 점에서 의미있는 논문이다.

## Introduction
당시 SOTA 모델이었던 Faster R-CANN은 가정한 bounding boxes의 픽셀과 특징들을 재샘플링 하는 과정을 거치고, high-quality classifier을 적용하였다.  
하지만 이런 방식은 고도의 연산 작업을 필요로 하기 때문에 속도면에서 성능이 떨어질 수 밖에 없다. 실제로 Faster R-CNN은 초당 7프레임을 작동시키는 7FPS의 성능을 보인 반면 YOLO는 45FPS, 
SDD는 59FPS로 나타났다. 
이러한 문제를 해결하고자 그동안 리샘플링을 하지 않는 시도가 많았으나 정확도가 떨어지는 모습들을 보였는데 SSD는 다음과 같은 개선방법들로 **속도와 정확성을 모두 잡는 모델**을 만들어냈다. 
- bounding box의 위치를 찾고 카테고리를 예측하기 위해 작은 컨볼루션 필터를 사용하였다.
- 종횡비(aspect ratios)가 다른 각각의 필터들을 사용하였다.
- 다양한 스케일에서의 인식을 위해 네트워크의 뒷부분에 위의 필터를을 적용하였다. 
위와 같은 방식을 통해 SSD는 PASCAL COV의 실시간 인식에서 74.3% mAP로 63.4% mAP를 보인 YOLO보다 높은 정확도를 보였다. 

## Model
![image](https://user-images.githubusercontent.com/76815825/117246200-292ba700-ae77-11eb-8c84-cec0b44670d0.png) 

SSD는 base network로 VGG16을 이용하였다. VGG16에는 FC레이어가 6,7,8로 세 개가 있는데 SDD에서는 6,7은 컨볼루션 레이어로 대체하였고 뒤에 보조적인 구조를 덧붙여 구성하였다. 
추가된 레이어를 살펴보면 p개의 채널을 가진 mxn feature layer에 대해 3x3xp의 커널을 적용하여 class socre와 bounding boxes를 예측할 수 있다. 
자세히 보면 다음과 같다. 

![image](https://user-images.githubusercontent.com/76815825/117247241-e1a61a80-ae78-11eb-87e7-1fcdd5c69d95.png) 

Pascal 데이터셋을 예로 설명하면, 3x3x(bouding box의 개수x(Class의 개수+좌표값(x,y,w,h))) = 3x3x(6x(Classes+4))가 **Classifier**가 된다.  
결과는 그림의 우측과 같이 각 bounding box별로 좌표값과 class score가 나오는 것을 볼 수 있다. 

SSD에서는 클래스 별로 **8732개의 bounding boxes**가 나오게 되는데 도출 과정은 다음과 같다. 
 
- conv4_3로부터 38x38x(4x(Classes+4)) = 5776x(Classes+4)  
- conv7로부터 19x19x(6x(Classes+4)) = 2166x(Classes+4) 
- conv8_2로부터 10x10x(6x(Classes+4)) = 600x(Classes+4) 
- conv9_2로부터 5x5x(6x(Classes+4)) = 150x(Classes+4) 
- conv10_2로부터 3x3x(4x(Classes+4)) = 36x(Classes+4) 
- conv11_2로부터 1x1x(4x(Classes+4)) = 4x(Classes+4) 
 
모두 더하면 8732x(Classes+4)

## Default boxes
 
앞서 보았듯이 feature map마다 Default boxes는 4개 혹은 6개가 만들어지는데 각각 다른 비율의 bounding box를 의미한다.   
식은 다음과 같다. 
  
  
![image](https://user-images.githubusercontent.com/76815825/117282221-73c11980-ae9f-11eb-85bf-7014c72838bc.png)   

Smin = 0.2, Smax = 0.9, m=6(feature map의 개수)로 k의 값만 1~6이 대입되어(k=1일 때 Smin, k=6일 때 Smax) 각 feature map마다 다른 s_k의 값을 가지게 된다. 비율은 s_k와 a_r이 대입되어 정해지는데 예를 들어 a_r=2라면 2:1의 비율이 될 것이다. 6개의 bounding boxes를 뽑을 때는 a_r의 5개 원소를 모두 사용하며, 추가적으로 더 작은 크기의 1:1 비율인 s_k'가 사용된다. 4개를 뽑을 때는 3과 1/3이 제외된다.  

## Loss function 
 
 ![image](https://user-images.githubusercontent.com/76815825/117286498-3dd26400-aea4-11eb-8fcd-50d2e5aded2e.png)
 
 SSD의 loss function은 분류에서의 손실값과 테두리 상자 설정에서의 손실값의 선형결합으로 이루어져있다. 
 - x:이미지, c:클래스, l:예측 테두리 상자, g:정답 테두리 상자
 - N: l과 g의 IOU가 0.5 이상인 상자의 수 

### Localization Loss
![image](https://user-images.githubusercontent.com/76815825/117287548-6f97fa80-aea5-11eb-8bf8-52f9595dad90.png) 
 
 - x^k_ij: k클래스에 대해 i번째 default box와 j번째 Ground Truth가 매칭되면(IOU>=0.5) 1, 아니면 0. 즉, 매칭된 박스에 대해서만 loss를 계산한다.
 - 예측 bouding box에서 좌표(x,y,w,h)의 조정값을 빼주어 smooth error loss를 구한다.

smooth error loss는 다음과 같다. 
![image](https://user-images.githubusercontent.com/76815825/117317771-c6f99300-aec4-11eb-9690-db5e0d810226.png)
 
 

### Confidence Loss
![image](https://user-images.githubusercontent.com/76815825/117290451-c94df400-aea8-11eb-9543-aa35e15af276.png) 
 
**Confidence Loss**는 매칭된 박스와 매칭되지 않은 박스에 대한 두 식으로 다시 한 번 나눠진다.   
전자의 경우 log(전체 클래스 확률/특정 클래스 확률)을, 후자의 경우 log(전체 클래스 확률/배경 클래스 확률)을 의미하는데 log1일 때 0으로 loss가 최소가 되므로 각각 특정 클래스, 배경 클래스의
확률을 높이는 방향으로 학습하게 된다. 즉, bouding box가 매칭되어 x^p_ij=1인 경우에는 특정 객체이므로 해당하는 클래스에 속할 확률이 높도록, 반대로 x^p_ij=0인 경우에는 객체가 아닌 배경이므로
배경클래스에 속할 확률이 높도록 학습하는 것이다. 












